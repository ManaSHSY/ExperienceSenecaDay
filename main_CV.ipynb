{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVKTJ/BC4j/gq+qYap+KoD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManaSHSY/ExperienceSenecaDay/blob/main/main_CV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insatll OpenCV and import required libraries"
      ],
      "metadata": {
        "id": "CkTsz8TeHaoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "E92pzXEKjVVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read a sample image, Dog as an example"
      ],
      "metadata": {
        "id": "65CvYa0kHiWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgage_Dog = cv2.imread('/Dog.jpeg')\n",
        "\n",
        "# Check if the image was loaded successfully\n",
        "if imgage_Dog is not None:\n",
        "    # Convert the image from BGR to RGB for correct display with matplotlib\n",
        "    imgage_Dog = cv2.cvtColor(imgage_Dog, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(imgage_Dog)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Error: Could not load image 'Cat.jpeg'. Please check the file path.\")"
      ],
      "metadata": {
        "id": "JiqMoxwXo65p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read a sample image, Cat as an example"
      ],
      "metadata": {
        "id": "NTJhlBkIHvRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_Cat = cv2.imread('/Cat.jpeg')\n",
        "# Check if the image was loaded successfully\n",
        "if image_Cat is not None:\n",
        "    # Convert the image from BGR to RGB for correct display with matplotlib\n",
        "    image_Cat = cv2.cvtColor(image_Cat, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(image_Cat)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Error: Could not load image 'Dog.jpeg'. Please check the file path.\")"
      ],
      "metadata": {
        "id": "94FjmBSApeX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Edge Detection with Canny. We can change the thresholds values"
      ],
      "metadata": {
        "id": "cU92cqYYOeo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image\n",
        "image_Lizard = cv2.imread('/Lizard.jpeg')\n",
        "\n",
        "# Convert to grayscale\n",
        "gray = cv2.cvtColor(image_Lizard, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply Gaussian blur to reduce noise\n",
        "blurred = cv2.GaussianBlur(gray, (3, 3), 1.4)\n",
        "\n",
        "# Apply Canny edge detection\n",
        "# Lower and upper thresholds for edge linking\n",
        "edges = cv2.Canny(blurred, threshold1=200, threshold2=300)\n",
        "\n",
        "# Display the original and edge-detected images\n",
        "plt.imshow(edges,cmap=('gray'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oZ9-9w72BUT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Color Standards. Let's try HSV and change it ..."
      ],
      "metadata": {
        "id": "QJLs8AXBO28W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_Fox = cv2.imread(\"/Fox.jpeg\")\n",
        "image_Fox = cv2.cvtColor(image_Fox, cv2.COLOR_BGR2RGB)\n",
        "hsv = cv2.cvtColor(image_Fox, cv2.COLOR_BGR2HSV)\n",
        "plt.imshow(image_Fox)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wjYOIoe_PH9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def changeHSVtoRGB(img, h = -1, s = -1, v = -1):\n",
        "    hue, sat, val = cv2.split(img)\n",
        "\n",
        "    if h != -1:\n",
        "        hue[:] = h\n",
        "    if s != -1:\n",
        "        sat = cv2.multiply(sat, s)\n",
        "    if v != -1:\n",
        "        val = cv2.add(val, v)\n",
        "    img = cv2.merge((hue, sat, val))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)\n",
        "    return img\n",
        "\n",
        "# Change V\n",
        "img_V = changeHSVtoRGB(hsv.copy(), v = 25)\n",
        "\n",
        "# Change S\n",
        "img_S = changeHSVtoRGB(hsv.copy(), s = 2)\n",
        "\n",
        "# Change H\n",
        "img_H = changeHSVtoRGB(hsv.copy(), h = 145)\n",
        "\n",
        "plt.imshow(img_H)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SYa1sHejDdwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filters and Convolutions"
      ],
      "metadata": {
        "id": "ymL3tY4SPmH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_Fall = cv2.imread('/Fall.jpeg')\n",
        "image_Fall = cv2.cvtColor(image_Fall, cv2.COLOR_BGR2RGB)\n",
        "image_Fall = cv2.resize(image_Fall, None, fx=0.1, fy=0.1)\n",
        "plt.imshow(image_Fall)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V6usdfgrSLLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = np.array([[ 0, -1,  0],\n",
        "                   [-1,  5, -1],\n",
        "                   [ 0, -1,  0]])\n",
        "\n",
        "# Apply the Sharpening Filter\n",
        "sharpened = cv2.filter2D(image_Fall, -1, kernel)\n",
        "sharpened = cv2.normalize(sharpened, None, 0, 255, cv2.NORM_MINMAX)\n",
        "plt.imshow(sharpened)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h6GxZp1SqSAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = np.array([[-2, -1, 0],\n",
        "                   [-1, 1, 1],\n",
        "                   [0, 1, 2]])\n",
        "\n",
        "# Apply the Embossed filter\n",
        "embossed = cv2.filter2D(image_Fall, -1, kernel)\n",
        "embossed = cv2.normalize(embossed, None, 0, 255, cv2.NORM_MINMAX)\n",
        "plt.imshow(embossed)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O9MyKtboycYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hybrid Images"
      ],
      "metadata": {
        "id": "Nua31q6RPuap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load two images\n",
        "image1 = cv2.imread('/Dog.jpeg')  # Low-frequency image\n",
        "image2 = cv2.imread('/Cat.jpeg')  # High-frequency image\n",
        "\n",
        "# Resize images to the same dimensions\n",
        "image1 = cv2.resize(image1, (600, 800))\n",
        "image2 = cv2.resize(image2, (600, 800))\n",
        "\n",
        "# Convert to grayscale\n",
        "image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "image2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
        "kernel_size = (91, 91)\n",
        "# Apply Gaussian blur to create a low-pass filter on the first image\n",
        "low_pass = cv2.GaussianBlur(image1_gray, kernel_size, 0)\n",
        "\n",
        "# Subtract a blurred version from the second image to get high frequencies\n",
        "blurred_image2 = cv2.GaussianBlur(image2_gray, kernel_size, 0)\n",
        "high_pass = cv2.subtract(image2_gray, blurred_image2)\n",
        "\n",
        "# Combine low-pass and high-pass images\n",
        "hybrid_image = cv2.add(low_pass , high_pass)\n",
        "#hybrid = cv2.addWeighted(low_pass, 0.5, high_pass, 0.5, 0)\n",
        "\n",
        "#hybrid_image = cv2.normalize(hybrid_image, None, 0, 255, cv2.NORM_MINMAX)\n",
        "plt.imshow(hybrid_image,cmap=('gray'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_R3yDkNE7wv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Blending and Creating a gif"
      ],
      "metadata": {
        "id": "OdZB4DewU-Z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load two images\n",
        "image_Horse = cv2.imread('/Horse.jpeg') # Source Image\n",
        "imgage_Turttle = cv2.imread('/Turttle.jpeg') # Destination Image\n",
        "\n",
        "# Resize images to the same dimensions\n",
        "image_Horse = cv2.resize(image1, (800, 800))\n",
        "imgage_Turttle = cv2.resize(image2, (800, 800))\n",
        "\n",
        "frames = []\n",
        "for alpha in np.linspace(0, 1, 30): # 30 frames\n",
        "    beta = 1 - alpha  # Complementary weight\n",
        "    blended_Image = cv2.addWeighted(image_Horse, alpha, imgage_Turttle, beta, 0)\n",
        "\n",
        "    # Convert BGR to RGB for saving with Pillow\n",
        "    blended_Image = cv2.cvtColor(blended_Image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Append frame as a Pillow Image\n",
        "    frames.append(Image.fromarray(blended_Image))\n",
        "\n",
        "# Save frames as a GIF\n",
        "frames[0].save('Animation.gif', save_all=True, append_images=frames[1:], duration=100, loop=0)\n",
        "\n",
        "print(\"GIF saved as 'Animation.gif'\")"
      ],
      "metadata": {
        "id": "MgysxOJhXr5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Panorama and Image Stiching"
      ],
      "metadata": {
        "id": "e5Hi7TNAVKNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of images to be stitched\n",
        "image_paths = ['/001.jpg', '/002.jpg','/003.jpg', '/004.jpg','/005.jpg', '/006.jpg','/007.jpg', '/008.jpg']\n",
        "images = [cv2.imread(img) for img in image_paths]\n",
        "\n",
        "# Create a Stitcher instance\n",
        "stitcher = cv2.Stitcher_create()\n",
        "\n",
        "# Perform stitching\n",
        "status, Stitched_Image = stitcher.stitch(images)\n",
        "\n",
        "if status == cv2.Stitcher_OK:\n",
        "    print(\"Stitching completed successfully.\")\n",
        "    # Display the result\n",
        "    Stitched_Image = cv2.cvtColor(Stitched_Image, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(Stitched_Image)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f\"Stitching failed with error code {status}.\")\n"
      ],
      "metadata": {
        "id": "RX5SYL6QVMoi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}